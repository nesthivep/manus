from fastapi import FastAPI, WebSocket, Request, BackgroundTasks, HTTPException, WebSocketDisconnect
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import asyncio
import os
import uuid
import json
import webbrowser
import threading
from pathlib import Path
from typing import Dict, List, Optional, Any
from contextlib import contextmanager
import time
from pydantic import BaseModel

from app.agent.manus import Manus
from app.flow.base import FlowType
from app.flow.flow_factory import FlowFactory
from app.logger import logger
from app.web.log_handler import capture_session_logs, get_logs
from app.web.thinking_tracker import ThinkingTracker, generate_thinking_steps

# æ§åˆ¶æ˜¯å¦è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ (è¯»å–ç¯å¢ƒå˜é‡ï¼Œé»˜è®¤ä¸ºTrue)
AUTO_OPEN_BROWSER = os.environ.get("AUTO_OPEN_BROWSER", "1") == "1"

app = FastAPI(title="OpenManus Web")

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
current_dir = Path(__file__).parent
# è®¾ç½®é™æ€æ–‡ä»¶ç›®å½•
app.mount("/static", StaticFiles(directory=current_dir / "static"), name="static")
# è®¾ç½®æ¨¡æ¿ç›®å½•
templates = Jinja2Templates(directory=current_dir / "templates")

# å­˜å‚¨æ´»è·ƒçš„ä¼šè¯åŠå…¶ç»“æœ
active_sessions: Dict[str, dict] = {}

# å­˜å‚¨ä»»åŠ¡å–æ¶ˆäº‹ä»¶
cancel_events: Dict[str, asyncio.Event] = {}

@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨äº‹ä»¶ï¼šåº”ç”¨å¯åŠ¨æ—¶è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨"""
    if AUTO_OPEN_BROWSER:
        # å»¶è¿Ÿ1ç§’ä»¥ç¡®ä¿æœåŠ¡å·²ç»å¯åŠ¨
        threading.Timer(1.0, lambda: webbrowser.open("http://localhost:8000")).start()
        print("ğŸŒ è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨...")

class SessionRequest(BaseModel):
    prompt: str

@app.get("/", response_class=HTMLResponse)
async def get_home(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

@app.post("/api/chat")
async def create_chat_session(session_req: SessionRequest, background_tasks: BackgroundTasks):
    session_id = str(uuid.uuid4())
    active_sessions[session_id] = {
        "status": "processing",
        "result": None,
        "log": []
    }
    
    # åˆ›å»ºå–æ¶ˆäº‹ä»¶
    cancel_events[session_id] = asyncio.Event()
    
    background_tasks.add_task(process_prompt, session_id, session_req.prompt)
    return {"session_id": session_id}

@app.get("/api/chat/{session_id}")
async def get_chat_result(session_id: str):
    if session_id not in active_sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    # ä½¿ç”¨æ–°çš„æ—¥å¿—å¤„ç†æ¨¡å—è·å–æ—¥å¿—
    session = active_sessions[session_id]
    session["log"] = get_logs(session_id)
    
    return session

@app.post("/api/chat/{session_id}/stop")
async def stop_processing(session_id: str):
    if session_id not in active_sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    if session_id in cancel_events:
        cancel_events[session_id].set()
        
    active_sessions[session_id]["status"] = "stopped"
    active_sessions[session_id]["result"] = "å¤„ç†å·²è¢«ç”¨æˆ·åœæ­¢"
    
    return {"status": "stopped"}

@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    try:
        await websocket.accept()
        
        if session_id not in active_sessions:
            await websocket.send_text(json.dumps({"error": "Session not found"}))
            await websocket.close()
            return
        
        session = active_sessions[session_id]
        
        # åˆå§‹çŠ¶æ€é€šçŸ¥
        await websocket.send_text(json.dumps({
            "status": session["status"], 
            "log": session["log"],
            "thinking_steps": ThinkingTracker.get_thinking_steps(session_id)
        }))
        
        # ç­‰å¾…ç»“æœæ›´æ–°
        last_log_count = 0
        last_thinking_step_count = 0
        
        while session["status"] == "processing":
            await asyncio.sleep(0.5)
            
            # æ£€æŸ¥æ—¥å¿—æ›´æ–°
            current_log_count = len(session["log"])
            if current_log_count > last_log_count:
                await websocket.send_text(json.dumps({
                    "status": session["status"],
                    "log": session["log"][last_log_count:]
                }))
                last_log_count = current_log_count
            
            # æ£€æŸ¥æ€è€ƒæ­¥éª¤æ›´æ–°
            thinking_steps = ThinkingTracker.get_thinking_steps(session_id)
            current_thinking_step_count = len(thinking_steps)
            if current_thinking_step_count > last_thinking_step_count:
                await websocket.send_text(json.dumps({
                    "status": session["status"],
                    "thinking_steps": thinking_steps[last_thinking_step_count:]
                }))
                last_thinking_step_count = current_thinking_step_count
            
            # æ£€æŸ¥ç»“æœæ›´æ–°
            if session["result"]:
                await websocket.send_text(json.dumps({
                    "status": session["status"],
                    "result": session["result"],
                    "log": session["log"][last_log_count:],
                    "thinking_steps": ThinkingTracker.get_thinking_steps(session_id, last_thinking_step_count)
                }))
        
        # å‘é€æœ€ç»ˆç»“æœ
        await websocket.send_text(json.dumps({
            "status": session["status"],
            "result": session["result"],
            "log": session["log"][last_log_count:],
            "thinking_steps": ThinkingTracker.get_thinking_steps(session_id, last_thinking_step_count)
        }))
        
        await websocket.close()
    except WebSocketDisconnect:
        # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œæ­£å¸¸æ“ä½œ
        pass
    except Exception as e:
        # å…¶ä»–å¼‚å¸¸ï¼Œè®°å½•æ—¥å¿—ä½†ä¸ä¸­æ–­åº”ç”¨
        print(f"WebSocketé”™è¯¯: {str(e)}")

# åœ¨é€‚å½“ä½ç½®æ·»åŠ LLMé€šä¿¡é’©å­
from app.web.thinking_tracker import ThinkingTracker

# ä¿®æ”¹é€šä¿¡è·Ÿè¸ªå™¨çš„å®ç°æ–¹å¼
class LLMCommunicationTracker:
    """è·Ÿè¸ªä¸LLMçš„é€šä¿¡å†…å®¹ï¼Œä½¿ç”¨monkey patchingä»£æ›¿å›è°ƒ"""
    
    def __init__(self, session_id: str, agent=None):
        self.session_id = session_id
        self.agent = agent
        self.original_run_method = None
        
        # å¦‚æœæä¾›äº†agentï¼Œå®‰è£…é’©å­
        if agent and hasattr(agent, "llm") and hasattr(agent.llm, "completion"):
            self.install_hooks()
    
    def install_hooks(self):
        """å®‰è£…é’©å­ä»¥æ•è·LLMé€šä¿¡å†…å®¹"""
        if not self.agent or not hasattr(self.agent, "llm"):
            return False
            
        # ä¿å­˜åŸå§‹æ–¹æ³•
        llm = self.agent.llm
        if hasattr(llm, "completion"):
            self.original_completion = llm.completion
            # æ›¿æ¢ä¸ºæˆ‘ä»¬çš„åŒ…è£…æ–¹æ³•
            llm.completion = self._wrap_completion(self.original_completion)
            return True
        return False
    
    def uninstall_hooks(self):
        """å¸è½½é’©å­ï¼Œæ¢å¤åŸå§‹æ–¹æ³•"""
        if self.agent and hasattr(self.agent, "llm") and self.original_completion:
            self.agent.llm.completion = self.original_completion
    
    def _wrap_completion(self, original_method):
        """åŒ…è£…LLMçš„completionæ–¹æ³•ä»¥æ•è·è¾“å…¥å’Œè¾“å‡º"""
        session_id = self.session_id
        
        async def wrapped_completion(*args, **kwargs):
            # è®°å½•è¾“å…¥
            prompt = kwargs.get('prompt', '')
            if not prompt and args:
                prompt = args[0]
            if prompt:
                ThinkingTracker.add_communication(session_id, "å‘é€åˆ°LLM", 
                                                prompt[:500] + ("..." if len(prompt) > 500 else ""))
            
            # è°ƒç”¨åŸå§‹æ–¹æ³•
            result = await original_method(*args, **kwargs)
            
            # è®°å½•è¾“å‡º
            if result:
                content = result
                if isinstance(result, dict) and 'content' in result:
                    content = result['content']
                elif hasattr(result, 'content'):
                    content = result.content
                
                if isinstance(content, str):
                    ThinkingTracker.add_communication(session_id, "ä»LLMæ¥æ”¶", 
                                                    content[:500] + ("..." if len(content) > 500 else ""))
            
            return result
        
        return wrapped_completion

# å¯¼å…¥æ–°åˆ›å»ºçš„LLMåŒ…è£…å™¨
from app.agent.llm_wrapper import LLMCallbackWrapper

# ä¿®æ”¹process_promptå‡½æ•°ï¼Œç¡®ä¿è®°å½•çœŸå®é€šä¿¡è€Œä¸æ˜¯æ¨¡æ‹Ÿæ•°æ®
async def process_prompt(session_id: str, prompt: str):
    try:
        # ä½¿ç”¨æ–°çš„æ—¥å¿—æ•è·ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        with capture_session_logs(session_id) as log:
            # åˆå§‹åŒ–æ€è€ƒè·Ÿè¸ª
            ThinkingTracker.start_tracking(session_id)
            ThinkingTracker.add_thinking_step(session_id, "å¼€å§‹å¤„ç†ç”¨æˆ·è¯·æ±‚")
            
            # ç›´æ¥è®°å½•ç”¨æˆ·è¾“å…¥çš„prompt
            ThinkingTracker.add_communication(session_id, "ç”¨æˆ·è¾“å…¥", prompt)
            
            # åˆå§‹åŒ–ä»£ç†å’Œä»»åŠ¡æµç¨‹
            ThinkingTracker.add_thinking_step(session_id, "åˆå§‹åŒ–AIä»£ç†å’Œä»»åŠ¡æµç¨‹")
            agent = Manus()
            
            # ä½¿ç”¨åŒ…è£…å™¨åŒ…è£…LLM
            if hasattr(agent, "llm"):
                original_llm = agent.llm
                wrapped_llm = LLMCallbackWrapper(original_llm)
                
                # æ³¨å†Œå›è°ƒå‡½æ•°
                def on_before_request(data):
                    # æå–è¯·æ±‚å†…å®¹
                    prompt_content = None
                    if data.get("args") and len(data["args"]) > 0:
                        prompt_content = str(data["args"][0])
                    elif data.get("kwargs") and "prompt" in data["kwargs"]:
                        prompt_content = data["kwargs"]["prompt"]
                    else:
                        prompt_content = str(data)
                    
                    # è®°å½•é€šä¿¡å†…å®¹
                    print(f"å‘é€åˆ°LLM: {prompt_content[:100]}...")
                    ThinkingTracker.add_communication(session_id, "å‘é€åˆ°LLM", prompt_content)
                
                def on_after_request(data):
                    # æå–å“åº”å†…å®¹
                    response = data.get("response", "")
                    response_content = ""
                    
                    # å°è¯•ä»ä¸åŒæ ¼å¼ä¸­æå–æ–‡æœ¬å†…å®¹
                    if isinstance(response, str):
                        response_content = response
                    elif isinstance(response, dict):
                        if "content" in response:
                            response_content = response["content"]
                        elif "text" in response:
                            response_content = response["text"]
                        else:
                            response_content = str(response)
                    elif hasattr(response, "content"):
                        response_content = response.content
                    else:
                        response_content = str(response)
                    
                    # è®°å½•é€šä¿¡å†…å®¹
                    print(f"ä»LLMæ¥æ”¶: {response_content[:100]}...")
                    ThinkingTracker.add_communication(session_id, "ä»LLMæ¥æ”¶", response_content)
                
                # æ³¨å†Œå›è°ƒ
                wrapped_llm.register_callback("before_request", on_before_request)
                wrapped_llm.register_callback("after_request", on_after_request)
                
                # æ›¿æ¢åŸå§‹LLM
                agent.llm = wrapped_llm
            
            flow = FlowFactory.create_flow(
                flow_type=FlowType.PLANNING,
                agents=agent,
            )
            
            # è®°å½•å¤„ç†å¼€å§‹
            ThinkingTracker.add_thinking_step(session_id, f"åˆ†æç”¨æˆ·è¯·æ±‚: {prompt[:50]}{'...' if len(prompt) > 50 else ''}")
            log.info(f"å¼€å§‹æ‰§è¡Œ: {prompt[:50]}{'...' if len(prompt) > 50 else ''}")
            
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¢«å–æ¶ˆ
            cancel_event = cancel_events.get(session_id)
            if cancel_event and cancel_event.is_set():
                log.warning("å¤„ç†å·²è¢«ç”¨æˆ·å–æ¶ˆ")
                ThinkingTracker.mark_stopped(session_id)
                active_sessions[session_id]["status"] = "stopped"
                active_sessions[session_id]["result"] = "å¤„ç†å·²è¢«ç”¨æˆ·åœæ­¢"
                return
            
            # è·Ÿè¸ªè®¡åˆ’åˆ›å»ºè¿‡ç¨‹
            ThinkingTracker.add_thinking_step(session_id, "åˆ›å»ºä»»åŠ¡æ‰§è¡Œè®¡åˆ’")
            ThinkingTracker.add_thinking_step(session_id, "å¼€å§‹æ‰§è¡Œä»»åŠ¡è®¡åˆ’")
            
            # ç§»é™¤æ‰‹åŠ¨æ¨¡æ‹Ÿæ­¥éª¤ï¼Œè®©çœŸå®çš„æµç¨‹æ‰§è¡Œç”Ÿæˆé€šä¿¡è®°å½•
            
            # æ‰§è¡Œå®é™…å¤„ç†
            result = await flow.execute(prompt)
            
            # è®°å½•å®Œæˆæƒ…å†µ
            log.info("å¤„ç†å®Œæˆ")
            ThinkingTracker.add_conclusion(session_id, "ä»»åŠ¡å¤„ç†å®Œæˆï¼å·²ç”Ÿæˆç»“æœã€‚")
            
            active_sessions[session_id]["status"] = "completed"
            active_sessions[session_id]["result"] = result
            active_sessions[session_id]["thinking_steps"] = ThinkingTracker.get_thinking_steps(session_id)
            
    except asyncio.CancelledError:
        # å¤„ç†å–æ¶ˆæƒ…å†µ
        print("å¤„ç†å·²å–æ¶ˆ")
        ThinkingTracker.mark_stopped(session_id)
        active_sessions[session_id]["status"] = "stopped"
        active_sessions[session_id]["result"] = "å¤„ç†å·²è¢«å–æ¶ˆ"
    except Exception as e:
        # å¤„ç†é”™è¯¯æƒ…å†µ
        error_msg = f"å¤„ç†å‡ºé”™: {str(e)}"
        print(error_msg)
        ThinkingTracker.add_error(session_id, f"å¤„ç†é‡åˆ°é”™è¯¯: {str(e)}")
        active_sessions[session_id]["status"] = "error"
        active_sessions[session_id]["result"] = f"å‘ç”Ÿé”™è¯¯: {str(e)}"
    finally:
        # æ¸…ç†èµ„æº
        if 'agent' in locals() and hasattr(agent, "llm") and isinstance(agent.llm, LLMCallbackWrapper):
            try:
                # æ­£ç¡®åœ°ç§»é™¤å›è°ƒ
                if 'on_before_request' in locals():
                    agent.llm._callbacks["before_request"].remove(on_before_request)
                if 'on_after_request' in locals():
                    agent.llm._callbacks["after_request"].remove(on_after_request)
            except (ValueError, Exception) as e:
                print(f"æ¸…ç†å›è°ƒæ—¶å‡ºé”™: {str(e)}")
                
        # æ¸…ç†å–æ¶ˆäº‹ä»¶
        if session_id in cancel_events:
            del cancel_events[session_id]

# æ·»åŠ ä¸€ä¸ªæ–°çš„APIç«¯ç‚¹æ¥è·å–æ€è€ƒæ­¥éª¤
@app.get("/api/thinking/{session_id}")
async def get_thinking_steps(session_id: str, start_index: int = 0):
    if session_id not in active_sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    return {
        "status": ThinkingTracker.get_status(session_id),
        "thinking_steps": ThinkingTracker.get_thinking_steps(session_id, start_index)
    }

# æ·»åŠ è·å–è¿›åº¦ä¿¡æ¯çš„APIç«¯ç‚¹
@app.get("/api/progress/{session_id}")
async def get_progress(session_id: str):
    if session_id not in active_sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    return ThinkingTracker.get_progress(session_id)
